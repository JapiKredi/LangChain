{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqqq pip --progress-bar off\n",
    "!pip install -qqq langchain==0.0.139 --progress-bar off\n",
    "!pip install -qqq openai==0.27.4 --progress-bar off\n",
    "!pip install -Uqqq watermark==2.3.1 --progress-bar off\n",
    "!pip install -Uqqq chromadb==0.3.21 --progress-bar off\n",
    "!pip install -Uqqq tiktoken==0.3.3 --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "# This line of code is a magic command in IPython that loads the 'watermark' extension.\n",
    "# The 'watermark' extension is a useful tool for documenting used Python modules, \n",
    "# their versions, and the machine characteristics. This can be helpful for reproducibility of computational environments.\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraies\n",
    "import os\n",
    "import openai\n",
    "\n",
    "import textwrap\n",
    "import chromadb\n",
    "import langchain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key by reading the folder path. Use this code if you're running the code on Google Colab. Otherwise, use the actual folder path\n",
    "folder_path = '/Users/jasper/Desktop/LangChain/'\n",
    "\n",
    "# Folder path\n",
    "os.chdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file containing the API key\n",
    "with open(folder_path + \"Jasper_OpenAI_API_Key.txt\", \"r\") as f:\n",
    "  openai.api_key = ' '.join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the OpenAI API key by updating the environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! model is not default parameter.\n",
      "                    model was transfered to model_kwargs.\n",
      "                    Please confirm that model is what you intended.\n"
     ]
    }
   ],
   "source": [
    "model = OpenAI(model = 'gpt-3.5-turbo-instruct', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Dunder Mifflin Paper Company - This is the fictional paper company where you work in the show. While there isn't an actual Dunder Mifflin office in Scranton, you can visit the building that was used as the exterior shot for the office in the show.\n",
      "\n",
      "2. Poor Richard's Pub - This is the bar where you and your coworkers often go for drinks and karaoke. In real life, Poor Richard's is a popular bar and restaurant in Scranton that often hosts Office-themed events and trivia nights.\n",
      "\n",
      "3. Steamtown National Historic Site - This train museum was featured in the episode \"The Convention\" where you and your coworkers attend a paper convention. You can visit the museum and see the train cars used in the show.\n",
      "\n",
      "4. Lake Scranton - This is the lake where you and your coworkers go for a company picnic in the episode \"The Merger.\" You can visit the lake and have a picnic of your own, just like in the show.\n",
      "\n",
      "5. The Electric City sign - This iconic sign is featured in the opening credits of the show and is a must-see for any Office fan. You can take a picture with the sign and even buy merchandise with the famous phrase \"Welcome to Scranton: The\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    model(\n",
    "        \"You're Dwight K. Schrute from the Office. Suggest 5 places to visit in Scranton that are connected to the TV show.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A Over a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    \"https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['page_content', 'metadata'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = documents[0]\n",
    "document.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\nTwitter's Recommendation Algorithm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEngineering\\n\\n\\n\\n\\n\\nBack\\n\\n\\n\\n\\n\\nEng\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! model is not default parameter.\n",
      "                    model was transfered to model_kwargs.\n",
      "                    Please confirm that model is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. The Twitter recommendation algorithm is like a beet farm, where we have to carefully select the\n",
      "best beets to sell to our customers. 2. Just like how Dwight carefully inspects each beet for\n",
      "quality, the algorithm inspects each tweet to determine its relevance. 3. The algorithm also uses a\n",
      "logistic regression model, which is like a Schrute family heirloom that has been passed down for\n",
      "generations. 4. Similar to how Dwight uses his knowledge of the beet farm to make decisions, the\n",
      "algorithm uses data from user interactions to make recommendations. 5. Ultimately, the algorithm's\n",
      "goal is to deliver the best tweets to your timeline, just like how Dwight strives to deliver the\n",
      "best beets to his customers.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'llm' is the language model you're using\n",
    "# Only specify the 'engine' parameter\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "# The rest of your code remains the same\n",
    "query = \"\"\"\n",
    "You're Dwight K. Schrute from the Office.\n",
    "Explain the Twitter recommendation algorithm in 5 sentences using analogies from the Office.\n",
    "\"\"\"\n",
    "print_response(index.query(query, llm=llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're Dwight K. Schrute from the Office.\n",
      "\n",
      "Paper sells are declining 10% year over year.\n",
      "\n",
      "Answer with analogies from the Office to the question and the way Dwight speaks.\n",
      "\n",
      "Question: How to sell paper?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You're Dwight K. Schrute from the Office.\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer with analogies from the Office to the question and the way Dwight speaks.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "print(\n",
    "    prompt.format(\n",
    "        context=\"Paper sells are declining 10% year over year.\",\n",
    "        question=\"How to sell paper?\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain the Twitter recommendation algorithm in 5 sentences\"\n",
    "response = chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Twitter recommendation algorithm is like a beet farm. It starts by gathering a large pool of\n",
      "potential Tweets from different sources, both from people you follow and those you don't. These\n",
      "Tweets are then ranked based on their relevance using a machine learning model. After ranking,\n",
      "filters and heuristics are applied to create a balanced and diverse feed. Finally, the algorithm\n",
      "blends the selected Tweets with other content like ads and recommendations before delivering them to\n",
      "your device. Just like Dwight's meticulous approach to farming, the algorithm carefully selects the\n",
      "best Tweets to show you on your timeline.\n"
     ]
    }
   ],
   "source": [
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
