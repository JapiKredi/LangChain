{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1Ils/e12+nTXsnOJNqpCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapiKredi/LangChain/blob/main/Langchain_complete_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwRQPY-6g8m3",
        "outputId": "6c954c89-8189-482f-da26-8914e0167443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/807.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/807.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m757.8/807.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-up environment"
      ],
      "metadata": {
        "id": "jNz8eUI6k1yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACE_API_KEY = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ],
      "metadata": {
        "id": "1JrOUVNFkr6Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get('openai_key')"
      ],
      "metadata": {
        "id": "Zw4x7KjBlNxE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "36tGOmsIxMJg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "rRqfNBh6veV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8I36Ej-vwdU",
        "outputId": "c6602864-c73b-4fee-f935-419bfcf56994"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature= 0.9)"
      ],
      "metadata": {
        "id": "wmhXKDK_vgBt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature= 0.9)"
      ],
      "metadata": {
        "id": "Ksr7GvHHvgI4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\""
      ],
      "metadata": {
        "id": "AWqXzD4WxEkZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.predict(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Kwmr46xEm_",
        "outputId": "a4d4e31c-3912-4793-b7e9-fbc5f2368403"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Steps\" or \"Chroma Socks\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USlI5d7pvgLV",
        "outputId": "36a6c4d9-8da9-4833-a1aa-e1de41dce41f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Soles\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2"
      ],
      "metadata": {
        "id": "UGJI4fXFzrKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature= 0.9)"
      ],
      "metadata": {
        "id": "tPvamMuixqAn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I want to open a restaurant for Indian Food. suggest a fency name for this.\""
      ],
      "metadata": {
        "id": "dTR2ZjJ3xqC7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iOS-YBgxqE4",
        "outputId": "db93a560-39e9-4dac-961a-2cd83b7e72c4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Spice Boulevard\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HuggingFace"
      ],
      "metadata": {
        "id": "eH_jVVaJtnmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFEM_OJSlT7g",
        "outputId": "1e11822b-71a7-485e-fc28-3748442a01ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "fB1unhnUoNtq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", huggingfacehub_api_token=HUGGINGFACE_API_KEY, model_kwargs={\"temperature\": 0.5})"
      ],
      "metadata": {
        "id": "VPOux9sIttZN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"translate English to German: How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DHFQdjV4twrU",
        "outputId": "5f56e5f3-6ee1-447e-ab42-8997c0d13ef6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wie sind Sie?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"translate English to German: How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HGczOMvUu2l0",
        "outputId": "cf3feccd-8ad5-426b-975e-1a688682d24e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wie sind Sie?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", huggingfacehub_api_token=HUGGINGFACE_API_KEY, model_kwargs={\"temperature\":0, \"max_length\":64})\n",
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llU5H_zAu6_e",
        "outputId": "cf781156-c7bd-41c1-c035-df7c8a179e22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese restaurant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm= HuggingFaceHub(repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',huggingfacehub_api_token=HUGGINGFACE_API_KEY, model_kwargs={'temperature':1})\n",
        "\n",
        "llm(\"Translate english to hindi : How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "QFBXwfDWvB7r",
        "outputId": "a2e9969a-74d3-4818-ba81-3cbd10ea51fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Translate english to hindi : How are you?\\n\\nTranslation of How are you in Hindi: आप कैसे हैं?\\n\\nAlso Read: How to say I love you in Hindi\\n\\n## How to say How are you in Hindi\\n\\nTo say How are you in Hindi, you can say आप कैसे हैं?\\n\\nThis is the most common way to ask someone how they are doing in Hindi.\\n\\nHere'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Templates"
      ],
      "metadata": {
        "id": "hI3MnedovUqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "p = prompt_template_name.format(cuisine=\"Bengali\")\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJJXvm1kvQz3",
        "outputId": "f67314c8-2357-4de6-d09c-4c13ae594a98"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for Bengali food. Suggest a fency name for this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['product'],\n",
        "    template = \"What is a good name for a company that makes {product}\"\n",
        ")\n",
        "\n",
        "p = prompt_template_name.format(product=\"colorful socks\")\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqCABqA-0q1s",
        "outputId": "41d23549-ab3f-4d0b-df70-2464592c2a4f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a company that makes colorful socks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response = chain.run('colorful socks')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmq0-lcm1Ay7",
        "outputId": "9f8b37e9-1a19-404c-ce71-c5e0b758409c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Rainbow Threads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tl74znlGvbAH",
        "outputId": "96f2da2a-701d-470d-86db-a75cd8849ca4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains"
      ],
      "metadata": {
        "id": "jI3-w8KQwMy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "akI49LoYwJeW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "response = chain.run('colorful socks')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbOxMUnywYOb",
        "outputId": "e661097e-4156-43b4-826d-fa70d8bee170"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"RainbowSocks Co.\" or \"VibrantVibes Socks\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt, verbose= True)\n",
        "response= chain.run(\"colorful socks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICYF1G6nwTPM",
        "outputId": "ce47f8a3-d214-44c8-ee71-18e05e75f168"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWhat is a good name for a company that makes colorful socks\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\"Rainbow Feet Co.\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a mistral LLM"
      ],
      "metadata": {
        "id": "-1mIw3cjye-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm= HuggingFaceHub(repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',huggingfacehub_api_token=HUGGINGFACE_API_KEY, model_kwargs={'temperature':1})"
      ],
      "metadata": {
        "id": "MDci_BHyyYfh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt, verbose= True)\n",
        "response= chain.run(\"colorful socks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JifSaiklypoj",
        "outputId": "4aa93568-adba-41a5-dd0f-09cc0fcc42b1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWhat is a good name for a company that makes colorful socks\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "What is a good name for a company that makes colorful socks?\n",
            "\n",
            "A good name for a company that makes colorful socks could be \"Vibrant Soles\" or \"Rainbow Feet\". These names play off the idea of bright, colorful socks and create a fun, playful image for the brand. Other options could include \"ChromaSocks\", \"Spectrum Socks\", or \"Color Crew Socks\". Ultimately, the name should reflect the unique and colorful nature of the socks and appeal to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Chain 1"
      ],
      "metadata": {
        "id": "Stgrmpzf0c5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "p = prompt_template_name.format(cuisine=\"Bengali\")\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAt5SaT1ysFd",
        "outputId": "65d080b3-298d-4808-d866-0abfdebb2a50"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for Bengali food. Suggest a fency name for this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response = chain.run('Bengali')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quwhy_tly9xR",
        "outputId": "540fc3ef-4e3b-44c0-f116-bd6884301f98"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Shonar Bangla Bistro\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Chain 2"
      ],
      "metadata": {
        "id": "boJKb0Ts14Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['product'],\n",
        "    template = \"What is a good name for a company that makes {product}\"\n",
        ")\n",
        "\n",
        "p = prompt_template_name.format(product=\"colorful socks\")\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOHBoNOh11P6",
        "outputId": "18581f90-7126-4ba8-ebdd-09f3dca9a9f8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a company that makes colorful socks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response = chain.run('colorful socks')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSZzz1Z19rG",
        "outputId": "117ca139-94e2-41d6-fbef-2b0ce104e081"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Threads\" or \"Chroma Sox\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Sequential Chain"
      ],
      "metadata": {
        "id": "B0yvutH82EIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.9)"
      ],
      "metadata": {
        "id": "-KgTVNVH2CsD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name1 = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restarant for {cuisine} food, can you suggest a name? \"\n",
        ")"
      ],
      "metadata": {
        "id": "cwVznen7488y"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name1)"
      ],
      "metadata": {
        "id": "4NWdSMaX5Bt2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name2 = PromptTemplate(\n",
        "    input_variables =['restarant_name'],\n",
        "    template = \"Can you suggest a menu for {restarant_name}\"\n",
        ")"
      ],
      "metadata": {
        "id": "U0uvE4I55I4b"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_chain = LLMChain(llm=llm, prompt=prompt_template_name2)"
      ],
      "metadata": {
        "id": "QDZMHqEy59Xq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ],
      "metadata": {
        "id": "uS6WA3tC5xuQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = SimpleSequentialChain(chains=[name_chain,item_chain])"
      ],
      "metadata": {
        "id": "YEUCWT9352sW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = chain.run('Indian')\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJjGVTym6JCp",
        "outputId": "70f865da-a7ff-4784-bbf3-d2c05828fe8a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            "1. \"Spice Haven\" Menu:\n",
            "Appetizer:\n",
            "- Samosas (crispy pastry filled with spiced potatoes and peas)\n",
            "- Chicken tikka skewers (tender marinated chicken pieces)\n",
            "- Vegetable pakoras (assorted vegetables in chickpea batter)\n",
            "\n",
            "Entrees:\n",
            "- Butter chicken (creamy tomato-based chicken curry)\n",
            "- Lamb vindaloo (spicy and tangy lamb curry)\n",
            "- Palak paneer (spinach and cottage cheese curry)\n",
            "- Aloo gobi (cauliflower and potato stir fry)\n",
            "- Chana masala (chickpea curry)\n",
            "\n",
            "Sides:\n",
            "- Garlic naan (soft and fluffy bread with garlic seasoning)\n",
            "- Basmati rice pilaf\n",
            "- Raita (yogurt sauce with cucumber and spices)\n",
            "\n",
            "Dessert:\n",
            "- Gulab jamun (fried dough balls soaked in sugar syrup)\n",
            "- Mango lassi (refreshing mango yogurt drink)\n",
            "\n",
            "2. \"Taste of India\" Menu:\n",
            "Appetizer:\n",
            "- Vegetable samosas (crispy pastry filled with spiced vegetables)\n",
            "- Tandoori shrimp (marinated and grilled shrimp)\n",
            "- Onion bhajis (deep-fried onion fritters)\n",
            "\n",
            "Entrees:\n",
            "- Chicken korma (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SequentialChain"
      ],
      "metadata": {
        "id": "KUmLdJjE7aJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
        "\n",
        "\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
      ],
      "metadata": {
        "id": "ZFKX8Nky6PAD"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")"
      ],
      "metadata": {
        "id": "zkgJ8SWt6Qi3"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain({\"cuisine\": \"indian\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSoi2ABi7kqX",
        "outputId": "9d3a3106-7620-43a8-d7ea-3a8c29fb3b7e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'indian', 'restaurant_name': '\\n\\n\"Saffron Spice House\"', 'menu_items': '\\n\\n1. Saffron Chicken Tikka Masala\\n2. Paneer Makhani with Saffron Rice\\n3. Lamb Korma with Saffron Pilaf\\n4. Saffron Shrimp Biryani\\n5. Saffron Vegetable Curry\\n6. Saffron Naan Bread\\n7. Saffron Falooda (dessert)\\n8. Saffron Lassi (drink)\\n9. Saffron-infused Basmati Rice\\n10. Saffron Roasted Cauliflower\\n11. Saffron Cardamom Chai\\n12. Saffron Kheer (rice pudding)\\n13. Saffron Mango Chicken Curry\\n14. Saffron Coconut Cashew Chicken\\n15. Saffron Pistachio Kulfi (ice cream)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'cuisine':'italian'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unu8Cz4c7swo",
        "outputId": "96955c9b-2a9d-414f-ef62-8dc89fe4f132"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'italian',\n",
              " 'restaurant_name': '\\n\\n\"Pasta Paradiso\"',\n",
              " 'menu_items': '\\n\\n1. Classic Spaghetti and Meatballs\\n2. Fettuccine Alfredo\\n3. Penne alla Vodka\\n4. Lasagna Bolognese\\n5. Mushroom Ravioli with Truffle Cream Sauce\\n6. Chicken Parmesan with Linguine\\n7. Shrimp Scampi over Angel Hair Pasta\\n8. Pesto Tortellini with Sun-Dried Tomatoes\\n9. Sausage and Peppers Rigatoni\\n10. Spicy Arrabbiata Penne\\n11. Baked Ziti with Marinara and Mozzarella\\n12. Seafood Linguine with White Wine Garlic Sauce\\n13. Eggplant Parmigiana with Spaghetti Marinara\\n14. Carbonara with Pancetta and Peas\\n15. Gnocchi with Pesto Cream Sauce and Grilled Chicken.'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({'cuisine':'italian'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGSYZf6d72hm",
        "outputId": "fcfb1bb0-e2d7-4e9b-dc14-4737ce6aa664"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'italian', 'restaurant_name': '\\n\\n\"Bella Cucina\"', 'menu_items': '\\n\\n1. Antipasto Platter - Assortment of cured meats, cheeses, olives, and marinated vegetables.\\n2. Margherita Pizza - Fresh basil, mozzarella, and tomato sauce on a wood-fired crust.\\n3. Pasta al Pomodoro - Spaghetti tossed in a homemade tomato sauce and topped with fresh basil.\\n4. Chicken Piccata - Tender chicken breasts in a lemon and caper sauce served with a side of roasted vegetables.\\n5. Eggplant Parmigiana - Layers of breaded eggplant, marinara sauce, and mozzarella cheese baked to perfection.\\n6. Shrimp Scampi - Juicy shrimp sautéed in garlic, white wine, and butter served over linguine.\\n7. Roasted Vegetable Panini - Grilled panini filled with roasted eggplant, zucchini, peppers, and goat cheese.\\n8. Lasagna Bolognese - Layers of pasta, meat sauce, and creamy ricotta cheese.\\n9. Tiramisu - Classic Italian dessert made with ladyfingers, coffee, and mascarpone cheese.\\n10. Gelato - Traditional Italian ice cream in various flavors such as pistachio, chocolate, and strawberry.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "eX3fvfoW9BF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpwXO4wg76MC",
        "outputId": "c48af0b1-fac5-42ad-b73f-a161d28697fc"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=439b94836fe0f0d0cf74fc120533791b300fef06bb3e710a455c19c975c237d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('SERPAPI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4rgz2wG8A5LB",
        "outputId": "488691c6-b40e-44b1-9802-dc593bca603d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'57897f911d79e2c8e4db2a076c178e47cd0c40eac037e782fafa7597128bf418'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['SERPAPI_API_KEY'] = SERPAPI_API_KEY"
      ],
      "metadata": {
        "id": "Q53K1zwL_zin"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "#Google Search API\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, SERPAPI_API_KEY=SERPAPI_API_KEY)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"What was the GDP of US in 2023?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ddjWcFBL_m9i",
        "outputId": "c41b6888-d9fa-4a0d-b705-05f26dd8bf2a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for the GDP of US in 2023\n",
            "Action: Search\n",
            "Action Input: \"GDP of US in 2023\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m$27.36 trillion\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to convert the GDP from dollars to another currency if needed\n",
            "Action: Calculator\n",
            "Action Input: $27.36 trillion\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 27360000000000\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should double check the accuracy of the GDP by searching for multiple sources\n",
            "Action: Search\n",
            "Action Input: \"GDP of US in 2023\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m$27.36 trillion\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The GDP of US in 2023 was $27.36 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The GDP of US in 2023 was $27.36 trillion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W09y-yC_qP9",
        "outputId": "3a0ccb1f-cd49-4d30-958f-74bc375ce146"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=142917df92a76b7e5a517410e44674e61699a5cf4ccc7410a4b020a3384366dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install this package: pip install wikipedia\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "1oYRtBuEBM-y",
        "outputId": "b7ee97ea-a458-4815-e747-f87fe9eb9ccb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find the release year of the film and then use the Calculator to raise it to the 0.43 power.\n",
            "Action: wikipedia\n",
            "Action Input: Departed film\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: The Departed\n",
            "Summary: The Departed is a 2006 American crime thriller film directed by Martin Scorsese and written by William Monahan. It is both a remake of the 2002 Hong Kong film Infernal Affairs and also loosely based on the real-life Boston Winter Hill Gang; the character Colin Sullivan is based on the corrupt FBI agent John Connolly, while the character Frank Costello is based on Irish-American gangster and crime boss Whitey Bulger. The film stars Leonardo DiCaprio, Matt Damon, Jack Nicholson, and Mark Wahlberg, with Martin Sheen, Ray Winstone, Vera Farmiga, Alec Baldwin, Anthony Anderson and James Badge Dale in supporting roles.\n",
            "The film takes place in Boston and the surrounding metro area, primarily in the South Boston neighborhood. Irish Mob boss Frank Costello (Nicholson) plants Colin Sullivan (Damon) as a spy within the Massachusetts State Police; simultaneously, the police assign undercover state trooper Billy Costigan (DiCaprio) to infiltrate Costello's mob crew. When both sides realize the situation, Sullivan and Costigan each attempt to discover the other's identity before they are found out.\n",
            "The Departed was a critical and commercial success, receiving acclaim for its direction, performances (particularly of DiCaprio, Nicholson, and Wahlberg), screenplay, and editing.\n",
            "It won several accolades, including four Oscars at the 79th Academy Awards: for Best Picture, Best Director, Best Adapted Screenplay, and Best Film Editing. It remains Scorsese's only personal Oscar win. The film also received six nominations each at the 64th Golden Globe Awards and the 60th British Academy Film Awards, and two nominations at the 13th Screen Actors Guild Awards.\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now that I know the release year, I can use the Calculator to raise it to the 0.43 power.\n",
            "Action: Calculator\n",
            "Action Input: 2006 ^ 0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 26.30281917656938\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'26.30281917656938'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory"
      ],
      "metadata": {
        "id": "uOPQnMlqB9KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "-bWmT4u-BTiD"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")"
      ],
      "metadata": {
        "id": "NeuM3uC-EKzw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJfEyf6nEN3n",
        "outputId": "674ce46a-a276-426e-a80a-b83c9a068d47"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"El Jardín de Sabores\" (The Garden of Flavors)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPMX31aLERKa",
        "outputId": "7c909c00-739f-4271-f1b8-58a45a947547"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Saffron Palace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okLwDfekEU6-",
        "outputId": "7a3d4438-38fb-45b3-ba98-402b42ef0d3d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConversationBufferMemory"
      ],
      "metadata": {
        "id": "nhHqgd4QEaUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYxcN4TOEXY5",
        "outputId": "b8d91e8b-fddf-4c2f-83ef-6a08c860682d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Casa de Sabor\" (House of Flavor)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDiLRG5gEdal",
        "outputId": "c21af02e-ee5e-4d42-8098-f20e4b92dced"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Maharaja's Palace\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYhewWP6EgNd",
        "outputId": "754d5f97-4e62-411c-8b7a-2e3ae27a76cd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\"Casa de Sabor\" (House of Flavor)\n",
            "Human: Indian\n",
            "AI: \n",
            "\"Maharaja's Palace\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Bengali\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfQ2OMfJEjvV",
        "outputId": "62643f89-c662-453f-9667-fcf466e450d7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Bengal Bistro\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj--90OtEnVK",
        "outputId": "7ceebdf4-d4fe-4ee4-bd05-1d6af4e8e12f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\"Casa de Sabor\" (House of Flavor)\n",
            "Human: Indian\n",
            "AI: \n",
            "\"Maharaja's Palace\" \n",
            "Human: Bengali\n",
            "AI: \n",
            "\n",
            "\"Bengal Bistro\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConversationChain"
      ],
      "metadata": {
        "id": "4A_dKclyEtsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIxpZAbFEp7e",
        "outputId": "b4b42c27-e6e7-48ef-91d8-360938be6f39"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "UhE3uQXeExDh",
        "outputId": "0d5877c1-812a-4fa8-d068-f32bfe0d90b0"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was held in 1975 and was won by the West Indies team. The tournament was organized by the International Cricket Council and was played in England. The final match was between the West Indies and Australia, with the West Indies winning by 17 runs. This was the first time that a cricket world cup was held and it was a major milestone in the history of the sport.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7ypodKeSE0IJ",
        "outputId": "fc9ecfbb-e009-4b95-e959-b870be422961"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "E8pzkZ_QE2wh",
        "outputId": "9f51ad8f-9e4f-4eab-f242-5c0f7df2aeab"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the West Indies team in the first cricket world cup was Clive Lloyd. He was a left-handed batsman and a medium-pace bowler. He led the team to victory with his strong leadership skills and impressive performance on the field. He also went on to captain the team in the next two cricket world cups in 1979 and 1983.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "JpZbzrOxE-If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=2)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PCR_zFnoE5ES",
        "outputId": "363e274b-e133-46ed-e77b-2021d15ea6eb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was won by the West Indies in 1975.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "n25MRt5FFBLR",
        "outputId": "3429b4a5-0432-4b14-8b35-0c7696dbf820"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  5+5 is equal to 10. Did you know that the first cricket world cup was held in England and was a 60-over per side tournament? The final match was played between the West Indies and Australia, with the West Indies winning by 17 runs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Z4KtyoqTFD4J",
        "outputId": "8c8358c2-fcf8-49bf-a985-b08423135c13"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning West Indies team was Clive Lloyd. Did you know that he also scored 102 runs in the final match? This was his first century in a one-day international match.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Loader"
      ],
      "metadata": {
        "id": "wGVTFLJoFHmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlE8tWkaFYNf",
        "outputId": "aa0a57f2-5123-4ae9-d6f9-2a1d2573e023"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/286.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m276.5/286.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "8d0M6V01FG7r"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader('/content/machine-learning-guidelines-2019.pdf')"
      ],
      "metadata": {
        "id": "4Dj-DDNdFk3z"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = loader.load"
      ],
      "metadata": {
        "id": "a-lvuU5yFsk2"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IexUeaTGF1z",
        "outputId": "f2b34103-d434-4345-f56c-ffeacbd60502"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method BaseLoader.load of <langchain_community.document_loaders.pdf.PyPDFLoader object at 0x7fc6afeefd90>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUCK1-TQGHUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}